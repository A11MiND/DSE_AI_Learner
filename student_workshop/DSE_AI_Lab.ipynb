{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bb0bf7",
   "metadata": {},
   "source": [
    "### Step 1: Setup Environment\n",
    "We need to install the necessary Python libraries and the `ngrok` tool to make our app accessible from the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f47e47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit pyngrok requests pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16da1d33",
   "metadata": {},
   "source": [
    "### Step 2: Install & Start AI Backend (Ollama)\n",
    "We will install **Ollama**, a tool that lets us run powerful AI models locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d079cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Ollama\n",
    "!curl -fsSL https://ollama.com/install.sh | sh\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# Start Ollama server in the background\n",
    "print(\"Starting Ollama Server...\")\n",
    "subprocess.Popen([\"ollama\", \"serve\"])\n",
    "time.sleep(5) # Give it a few seconds to start\n",
    "print(\"Ollama is running! ðŸ¦™\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40ed79b",
   "metadata": {},
   "source": [
    "### Step 3: Download the AI Model\n",
    "We will use `llava` (Large Language-and-Vision Assistant), a model that can see images and chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0245ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading AI Model (this may take a minute)...\")\n",
    "!ollama pull llava\n",
    "print(\"Model downloaded! âœ…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f1123",
   "metadata": {},
   "source": [
    "### Step 4: Write the App Code\n",
    "Here is the Python code for our AI Tutor app. \n",
    "**Task**: Read through the code below. Can you find where we define the `system_prompt`? Try changing it to give the AI a different personality!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79964529",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile app.py\n",
    "import streamlit as st\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "# --- Configuration ---\n",
    "OLLAMA_URL = \"http://localhost:11434\"\n",
    "MODEL_NAME = \"llava\"\n",
    "\n",
    "# ðŸŽ¨ UI Setup\n",
    "st.set_page_config(page_title=\"My DSE AI Tutor\", page_icon=\"ðŸ¤–\")\n",
    "st.title(\"ðŸ¤– DSE ICT AI Tutor\")\n",
    "st.caption(\"Powered by Ollama & Streamlit\")\n",
    "\n",
    "# ðŸ§  AI Logic\n",
    "def ask_ai(image_bytes, user_question):\n",
    "    url = f\"{OLLAMA_URL}/api/generate\"\n",
    "    \n",
    "    # Convert image to format AI understands (Base64)\n",
    "    img_b64 = base64.b64encode(image_bytes).decode('utf-8')\n",
    "    \n",
    "    # Instructions for the AI\n",
    "    system_prompt = \"You are a helpful DSE ICT Tutor. Explain concepts clearly to a secondary school student.\"\n",
    "    full_prompt = f\"{system_prompt}\\n\\nQuestion: {user_question}\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": MODEL_NAME,\n",
    "        \"prompt\": full_prompt,\n",
    "        \"images\": [img_b64],\n",
    "        \"stream\": False\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        return response.json().get(\"response\", \"Error: No response\")\n",
    "    except Exception as e:\n",
    "        return f\"Connection Error: {e}\"\n",
    "\n",
    "# ðŸ’¬ Chat Interface\n",
    "if \"messages\" not in st.session_state:\n",
    "    st.session_state.messages = []\n",
    "\n",
    "# Display History\n",
    "for msg in st.session_state.messages:\n",
    "    with st.chat_message(msg[\"role\"]):\n",
    "        st.write(msg[\"content\"])\n",
    "        if \"image\" in msg:\n",
    "            st.image(msg[\"image\"], width=200)\n",
    "\n",
    "# Input Area\n",
    "uploaded_file = st.file_uploader(\"Upload an image (Question/Diagram)\", type=[\"png\", \"jpg\", \"jpeg\"])\n",
    "user_input = st.chat_input(\"Ask a question about the image...\")\n",
    "\n",
    "if user_input and uploaded_file:\n",
    "    # Show User Message\n",
    "    with st.chat_message(\"user\"):\n",
    "        st.write(user_input)\n",
    "        st.image(uploaded_file, width=200)\n",
    "    \n",
    "    # Save to history\n",
    "    st.session_state.messages.append({\n",
    "        \"role\": \"user\", \n",
    "        \"content\": user_input,\n",
    "        \"image\": uploaded_file.getvalue()\n",
    "    })\n",
    "    \n",
    "    # Get AI Response\n",
    "    with st.chat_message(\"assistant\"):\n",
    "        with st.spinner(\"Thinking...\"):\n",
    "            response = ask_ai(uploaded_file.getvalue(), user_input)\n",
    "            st.write(response)\n",
    "    \n",
    "    # Save AI response\n",
    "    st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "elif user_input and not uploaded_file:\n",
    "    st.warning(\"Please upload an image first! This is a Vision AI demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa10a2c2",
   "metadata": {},
   "source": [
    "### Step 5: Launch the App!\n",
    "Run the cell below. It will generate a link (e.g., `http://xxxx.ngrok-free.app`). Click it to open your app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435fa60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyngrok import ngrok\n",
    "\n",
    "# Kill any existing tunnels\n",
    "ngrok.kill()\n",
    "\n",
    "# Create tunnel\n",
    "public_url = ngrok.connect(8501).public_url\n",
    "print(f\"ðŸš€ Your App is Live! Click here: {public_url}\")\n",
    "\n",
    "# Run the app\n",
    "!streamlit run app.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
